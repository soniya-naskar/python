{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49f41b4-b20f-48d3-a993-1591f683f3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#quest-1\n",
    "R-squared is a statistical measure that represents the proportion of the variance in the dependent variable that is explained by the independent variable(s) in a regression model.\n",
    "Its a crucial metric for evaluating the goodness of fit of a linear regression model.\n",
    "R-squared = 1 - (Sum of Squared Residuals / Total Sum of Squares)\n",
    "\n",
    "#quest-2\n",
    "R-squared only measures the proportion of variance explained by the model.   \n",
    "Adjusted R-squared considers both the proportion of variance explained and the number of predictors in the model.\n",
    "\n",
    "#quest-3\n",
    "Adjusted R-squared is a valuable tool for model selection and evaluation when you are working with multiple predictors. \n",
    "It provides a more accurate assessment of the models performance by considering both the explained variance and the models complexity.\n",
    "\n",
    "#quest-4\n",
    "These metrics are used to evaluate the performance of a regression model by quantifying the difference between predicted and actual values.\n",
    "Mean Squared Error (MSE): The average of the squared differences between the predicted and actual values.\n",
    "Root Mean Squared Error (RMSE): The square root of the MSE.\n",
    "Mean Absolute Error (MAE): The average of the absolute differences between the predicted and actual values.\n",
    "These metrics provide valuable insights into the accuracy of a regression model. By understanding their strengths and weaknesses, you can select the most appropriate metric for your specific use case.   \n",
    "\n",
    "#quest-5\n",
    "Mean Squared Error (MSE)\n",
    "Advantages:Widely used and understood metric.\n",
    "Disadvantages:Sensitive to outliers due to squaring the errors.\n",
    "\n",
    "Root Mean Squared Error (RMSE)\n",
    "Advantages:Same units as the original data, making it easier to interpret.\n",
    "Widely used and understood metric.\n",
    "Disadvantages:Still sensitive to outliers due to the underlying MSE calculation.\n",
    "\n",
    "Mean Absolute Error (MAE)\n",
    "Advantages:Robust to outliers as it uses absolute values.\n",
    "Disadvantages:Less sensitive to large errors compared to MSE and RMSE.\n",
    "\n",
    "#quest-6\n",
    "Lasso Regularization-L1 Regularization: Adds the absolute value of the coefficients to the loss function\n",
    "Ridge Regularization-L2 Regularization: Adds the square of the coefficients to the loss function.\n",
    "Lasso is better for feature selection, while Ridge is better for handling multicollinearity. \n",
    "The choice between the two often depends on the specific characteristics of the data and the desired outcome.\n",
    "\n",
    "#quest-7\n",
    "Regularized linear models modify the standard linear regression loss function by adding a penalty term based on the magnitude of the models coefficients. \n",
    "This penalty term pushes the coefficients towards zero, resulting in a simpler model\n",
    "eg-regularized linear models help prevent overfitting by introducing a bias-variance trade-off. By adding a penalty term, the model becomes slightly biased (towards simpler models) but reduces variance (sensitivity to noise). \n",
    "This trade-off often leads to improved performance on unseen data.\n",
    "\n",
    "#quest-8\n",
    "Regularized linear models assume a linear relationship between the dependent and independent variables. If the underlying relationship is nonlinear, these models may not perform well.\n",
    "Selecting the optimal regularization parameter (lambda) is critical. An incorrect value can lead to underfitting or overfitting. \n",
    "The performance of regularized models can be significantly affected by the scale of the features. Its crucial to standardize or normalize features before applying regularization.\n",
    "\n",
    "#quest-9\n",
    "Model B will be the better performer as smaller the error higher is the accuracy.\n",
    "Compared to RMSE (Root Mean Squared Error), MAE does n0t penalize large errors as heavily. \n",
    "This can be a drawback in scenarios where large errors are particularly costly or undesirable.\n",
    "\n",
    "#quest-10\n",
    "Model A will give more accuracy\n",
    "Unlike Lasso regression, Ridge regression does not perform feature selection. It shrinks coefficients towards zero but does not eliminate them entirely. This can lead to models with a larger number of features than necessary."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
